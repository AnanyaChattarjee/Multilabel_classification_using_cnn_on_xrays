{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport pathlib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchvision.models as models\nimport torch\nfrom torchsummary import summary","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"single_img = plt.imread(\"/kaggle/input/data/images_001/images/00000001_000.png\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(single_img, cmap=\"gray\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/data/Data_Entry_2017.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_columns =list(data.columns)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"useful_columns = all_columns[0:2]+all_columns[7:11]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"useful_columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"useful_data = data[useful_columns]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path_list = list()\nfile_names = list()\nfor absolute_path in pathlib.Path(\"/kaggle/input/data\").glob(\"images_*/images/*.png\"):\n    \n    path_list.append(str(absolute_path))                \n    file_names.append(str(absolute_path).split(\"/\")[-1])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path_list.sort()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path_list","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"useful_data[\"Image Path\"]= path_list","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"useful_data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unique_diseases = set()\n\nfor disease in useful_data[\"Finding Labels\"]:\n    unique_diseases.update(set(disease.split(\"|\")))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unique_diseases = list(unique_diseases)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unique_diseases.remove(\"No Finding\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unique_diseases","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"diseases2idx = dict(zip(unique_diseases , range(len(unique_diseases))))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"diseases2idx","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"another_data = pd.read_csv(\"/kaggle/input/data/BBox_List_2017.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"another_data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"b_box = pd.DataFrame(another_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = pd.DataFrame(useful_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"columns_to_drop = b_box[\"Image Index\"]\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"columns_to_drop","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = train_data[train_data['Image Index'].isin(columns_to_drop)]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = train_data[~train_data['Image Index'].isin(columns_to_drop)]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train =  train_data[\"Finding Labels\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"raw","source":"diseases2idx","metadata":{}},{"cell_type":"code","source":"y_train =list()\nfor single_img_labels in train_data[\"Finding Labels\"]:\n    single_img_multi_hot_vector = np.zeros((len(diseases2idx,)))\n    diseases = single_img_labels.split(\"|\")\n    if \"No Finding\" not in diseases:\n        for single_diseases in diseases:\n            single_img_multi_hot_vector[diseases2idx[single_diseases]]=1.0\n    y_train.append(single_img_multi_hot_vector)\ny_train = np.array(y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_test =list()\nfor single_img_labels in test_data[\"Finding Labels\"]:\n    single_img_multi_hot_vector = np.zeros((len(diseases2idx,)))\n    diseases = single_img_labels.split(\"|\")\n    if \"No Finding\" not in diseases:\n        for single_diseases in diseases:\n            single_img_multi_hot_vector[diseases2idx[single_diseases]]=1.0\n    y_test.append(single_img_multi_hot_vector)\ny_test = np.array(y_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_test","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_test.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def training_data_mini_batches_generator(training_data_df, mb_size=10):\n    \n    for i in range (training_data_df.shape[0]//mb_size):\n\n        img_np_array_mb_list = list()\n        \n        for j in range(i*mb_size,(i+1)*mb_size):\n            \n            single_img_path  = train_data[\"Image Path\"].iloc[j]\n            img_np_array = plt.imread(single_img_path)\n\n            resized_img_np_array = cv2.resize(img_np_array,(224,224))\n            if len(resized_img_np_array.shape) == 2 or resized_img_np_array.shape[2] == 1:\n            # grayscale image (H, W) or (H, W, 1)\n                three_channel_np_array = cv2.cvtColor(resized_img_np_array, cv2.COLOR_GRAY2RGB)\n            elif resized_img_np_array.shape[2] == 4:\n            # image with 4 channels (e.g., RGBA) â†’ drop alpha\n                three_channel_np_array = resized_img_np_array[:, :, :3]\n            else:\n            # already 3 channels\n                three_channel_np_array = resized_img_np_array\n\n            img_np_array_mb_list.append(three_channel_np_array)\n\n        x_train_mb = np.array(img_np_array_mb_list)\n        y_train_mb = y_train[i*mb_size:(i+1)*mb_size,:]\n\n        yield x_train_mb,y_train_mb\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"our_training_datagen = training_data_mini_batches_generator(train_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_mb , y_train_mb = our_training_datagen.__next__()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class our_custom_resnet50_cnn(torch.nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n\n        self.resnet50_full_net = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n\n        for param in self.resnet50_full_net.parameters():\n            param.requires_grad = False\n\n        self.resnet50_full_net.fc = torch.nn.Sequential(\n            torch.nn.Linear(self.resnet50_full_net.fc.in_features, num_classes),\n            torch.nn.Sigmoid()  \n        )\n\n    def forward(self, x):\n        \n        y_pred_mb =  self.resnet50_full_net(x)\n        return y_pred_mb","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"our_model = our_custom_resnet50_cnn(num_classes=14)\nour_model = our_model.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"summary(our_model, input_size = (3,224,224))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test_data_mini_batches_generator(test_data_df, mb_size=10):\n    for i in range(test_data_df.shape[0] // mb_size):\n        img_mb_list = []\n        meta_mb_list = []\n\n        for j in range(i * mb_size, (i + 1) * mb_size):\n            # Image path & loading\n            img_path = test_data_df[\"Image Path\"].iloc[j]\n            img = plt.imread(img_path)\n\n            # Original size\n            ow = test_data_df[\"OriginalImage[Width\"].iloc[j]\n            oh = test_data_df[\"Height]\"].iloc[j]\n            spacing_x = test_data_df[\"OriginalImagePixelSpacing[x\"].iloc[j]\n            spacing_y = test_data_df[\"y]\"].iloc[j]\n\n            # Resize\n            img_resized = cv2.resize(img, (224, 224))\n            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_GRAY2RGB)\n            img_rgb = img_rgb.transpose((2, 0, 1))  # CHW format\n\n            # Scale spacings\n            scaled_spacing_x = (ow / 224) * spacing_x\n            scaled_spacing_y = (oh / 224) * spacing_y\n\n            img_mb_list.append(img_rgb)\n            meta_mb_list.append([scaled_spacing_x, scaled_spacing_y])\n\n        # Convert to tensors\n        x_img_mb = np.array(img_mb_list).astype(np.float32) / 255.0\n        x_meta_mb = np.array(meta_mb_list).astype(np.float32)\n        y_mb = y_test[i * mb_size:(i + 1) * mb_size, :]\n\n        yield (x_img_mb, x_meta_mb), y_mb\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"our_testing_datagen = test_data_mini_batches_generator(test_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test_mb , y_test_mb = our_testing_datagen.__next__()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test_mb","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss_func = torch.nn.BCELoss()\noptimizer = torch.optim.SGD(params = our_model.parameters(),lr=0.01)\nepochs = 5\nmb_size = 10\n\nfor i in range(epochs):\n\n    our_training_data_gen = training_data_mini_batches_generator(train_data)\n    \n    for x_train_mb,y_train_mb in our_training_data_gen:\n\n        x_train_mb = torch.tensor(x_train_mb, dtype=torch.float32).permute(0, 3, 1, 2).to(device)  # Numpy -> Tensor + channel-first\n        y_train_mb = torch.tensor(y_train_mb, dtype=torch.float32).to(device)\n\n\n    y_pred_mb_train = our_model(x_train_mb)\n    training_mb_loss = loss_func(y_pred_mb_train,y_train_mb)\n\n    training_mb_loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n    print(\"Epoch # {}, Training Loss Value = {}\".format(i+1,training_mb_loss))\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}